{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCiqb1zbynkx"
   },
   "source": [
    "# Topic modelling for InnerSpeech dataset (Japanese)\n",
    "\n",
    "\n",
    "Author : Romy Beauté\\\n",
    "Date created : 02/12/2024\\\n",
    "Last modified : 25/02/2025\\\n",
    "Corresp : r.beaut@sussex.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulJbWFMhOg8k"
   },
   "source": [
    "Selection of sentence transformer embedding models :\n",
    "https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "The all-mpnet-base-v2 model provides the best quality, while all-MiniLM-L6-v2 is 5 times faster and still offers good quality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script directory: /Users/rbeaute/Projects/MOSAIC\n",
      "Added /Users/rbeaute/Projects/MOSAIC/MULTILINGUAL to Python path\n",
      "DATA directory: /Users/rbeaute/Projects/MOSAIC/DATA/multilingual/japanese/innerspeech\n",
      "Cache directory: /Users/rbeaute/Projects/MOSAIC/DATA/multilingual/japanese/innerspeech/cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rbeaute/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# !pip install bertopic accelerate bitsandbytes xformers adjustText\n",
    "# !pip install llama-cpp-python\n",
    "# !{sys.executable} -m pip install \"scipy==1.9.0\" \"scikit-image==0.23.2\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from bertopic.backend import languages\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "nltk.download('stopwords')\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "print(\"Script directory:\", script_dir)\n",
    "multilingual_dir = os.path.join(script_dir, 'MULTILINGUAL')\n",
    "sys.path.append(multilingual_dir)\n",
    "print(f\"Added {multilingual_dir} to Python path\")\n",
    "\n",
    "from multiling_helpers import JapaneseProcessor, TopicModeler\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# SET PARAMS FOR DATASET\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "project = \"multilingual\"\n",
    "dataset = \"innerspeech\" \n",
    "language = \"japanese\"\n",
    "#check that chosen language is supported by BERTopic internal language\n",
    "if language not in languages:\n",
    "    raise ValueError(f\"Language '{language}' is not supported. Supported languages are: {languages}\")\n",
    "\n",
    "DATA_dir = os.path.join(script_dir, f'DATA/{project}/{language}/{dataset}')\n",
    "print(\"DATA directory:\", DATA_dir)\n",
    "\n",
    "cache_dir = os.path.join(DATA_dir, \"cache\")\n",
    "print(\"Cache directory:\", cache_dir)\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "\n",
    "save_reports = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 columns: ['タイムスタンプ', '性別（自認）を教えて下さい', '年齢を教えて下さい', '上の動画がどれだけ自分の内言として当てはまりますか？', '上の動画がどれだけ自分の内言として当てはまりますか？.1', '上の動画がどれだけ自分の内言として当てはまりますか？.2', '上の動画がどれだけ自分の内言として当てはまりますか？.3', '上の動画がどれだけ自分の内言として当てはまりますか？.4', '上の動画がどれだけ自分の内言として当てはまりますか？.5', '上の動画がどれだけ自分の内言として当てはまりますか？.6', '上記とは異なる内言で思考している場合は教えて下さい（任意）', '上の動画がどれだけ自分の内言として当てはまりますか？.7', '上の動画がどれだけ自分の内言として当てはまりますか？.8', '上の動画がどれだけ自分の内言として当てはまりますか？.9', '上の動画がどれだけ自分の内言として当てはまりますか？.10', '上の動画がどれだけ自分の内言として当てはまりますか？.11', '上の動画がどれだけ自分の内言として当てはまりますか？.12', '上の動画がどれだけ自分の内言として当てはまりますか？.13', '上記とは異なる内言で思考している場合は教えて下さい（任意）.1', '上の動画がどれだけ自分の内言として当てはまりますか？.14', '上の動画がどれだけ自分の内言として当てはまりますか？.15', '上の動画がどれだけ自分の内言として当てはまりますか？.16', '上の動画がどれだけ自分の内言として当てはまりますか？.17', '上の動画がどれだけ自分の内言として当てはまりますか？.18', '上の動画がどれだけ自分の内言として当てはまりますか？.19', '上の動画がどれだけ自分の内言として当てはまりますか？.20', '上記とは異なる内言で思考している場合は教えて下さい（任意）.2', '内言の中に「視覚」は', '内言の中に「聴覚」は', '内言の中に「嗅覚」は', '内言の中に「味覚」は', '内言の中に「触覚」は', 'あなたの内言は，', 'メールを書くときに，頭の中だけで（メモなどを取らずに）事前に文面を組み立てることは可能ですか？', '粘土細工をつくるときに，頭の中だけで（スケッチなどをせずに）事前に完成イメージを思い浮かべることは可能ですか？', 'どれだけあなたの内言は自らの意思決定に影響を与えますか？', 'どれだけ自分自身の内言を鮮明に自覚できますか？', '内言について他に述べたいことがあれば自由に記述してください（任意）']\n",
      "Columns with non-numeric values (n=7): ['タイムスタンプ', '性別（自認）を教えて下さい', '年齢を教えて下さい', '上記とは異なる内言で思考している場合は教えて下さい（任意）', '上記とは異なる内言で思考している場合は教えて下さい（任意）.1', '上記とは異なる内言で思考している場合は教えて下さい（任意）.2', '内言について他に述べたいことがあれば自由に記述してください（任意）']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reports_path = os.path.join(DATA_dir,f\"{dataset}.xlsx\")\n",
    "df = pd.read_excel(reports_path)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "colnames = pd.read_excel(reports_path).columns.tolist()\n",
    "print(len(colnames), \"columns:\", colnames)\n",
    "\n",
    "non_numeric_cols = df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "print(f\"Columns with non-numeric values (n={len(non_numeric_cols.tolist())}):\", non_numeric_cols.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-numeric columns translated:\n",
    "\n",
    "1. Timestamp\n",
    "2. Gender (self-identified)\n",
    "3. Age\n",
    "4. If you think in different inner speech than above, please tell us (optional)\n",
    "5. If you think in different inner speech than above, please tell us (optional).1\n",
    "6. If you think in different inner speech than above, please tell us (optional).2\n",
    "7. Please freely describe anything else about inner speech (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate non-numeric variables (that might contain verbal reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>タイムスタンプ</th>\n",
       "      <th>性別（自認）を教えて下さい</th>\n",
       "      <th>年齢を教えて下さい</th>\n",
       "      <th>上記とは異なる内言で思考している場合は教えて下さい（任意）</th>\n",
       "      <th>上記とは異なる内言で思考している場合は教えて下さい（任意）.1</th>\n",
       "      <th>上記とは異なる内言で思考している場合は教えて下さい（任意）.2</th>\n",
       "      <th>内言について他に述べたいことがあれば自由に記述してください（任意）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-11 17:46:55.621</td>\n",
       "      <td>男性</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-11 17:48:16.588</td>\n",
       "      <td>男性</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-11 17:49:03.556</td>\n",
       "      <td>女性</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-11 17:49:33.625</td>\n",
       "      <td>男性</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-11 17:49:48.730</td>\n",
       "      <td>女性</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  タイムスタンプ 性別（自認）を教えて下さい 年齢を教えて下さい  \\\n",
       "0 2022-05-11 17:46:55.621            男性        35   \n",
       "1 2022-05-11 17:48:16.588            男性        26   \n",
       "2 2022-05-11 17:49:03.556            女性        21   \n",
       "3 2022-05-11 17:49:33.625            男性        34   \n",
       "4 2022-05-11 17:49:48.730            女性        53   \n",
       "\n",
       "  上記とは異なる内言で思考している場合は教えて下さい（任意） 上記とは異なる内言で思考している場合は教えて下さい（任意）.1  \\\n",
       "0                           NaN                             NaN   \n",
       "1                           NaN                             NaN   \n",
       "2                           NaN                             NaN   \n",
       "3                           NaN                             NaN   \n",
       "4                           NaN                             NaN   \n",
       "\n",
       "  上記とは異なる内言で思考している場合は教えて下さい（任意）.2 内言について他に述べたいことがあれば自由に記述してください（任意）  \n",
       "0                             NaN                               NaN  \n",
       "1                             NaN                               NaN  \n",
       "2                             NaN                               NaN  \n",
       "3                             NaN                               NaN  \n",
       "4                             NaN                               NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df of non-numeric columns\n",
    "df_non_numeric = df[non_numeric_cols]\n",
    "df_non_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-numeric columns translated:\n",
    "\n",
    "1. If you think in different inner speech than above, please tell us (optional)\n",
    "2. If you think in different inner speech than above, please tell us (optional).1\n",
    "3. If you think in different inner speech than above, please tell us (optional).2\n",
    "4. Please freely describe anything else about inner speech (optional)\n",
    "\n",
    "\n",
    "Participants were asked several questions in 3 different situations.\n",
    "The situations were illustrated with videos: \n",
    "- A situation where you are looking for your wallet\n",
    "- A situation where you are thinking about buying a car\n",
    "- A situation where you are thinking about lunch\n",
    "After they rated videos which explain different types of inner speech, the following question was asked:\\\n",
    "**Question: \"If you are thinking in a different way, please write it down (optional)\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5365\n",
      "1313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wallet_answer</th>\n",
       "      <th>car_answer</th>\n",
       "      <th>lunch_answer</th>\n",
       "      <th>reflection_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>自分の動きを考えるときは、漫画のネームみたいな感じで思い浮かべる</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>味と匂いを想像し、それをいま自分が欲しているのかを自らに問う</td>\n",
       "      <td>他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>基本は回答した通り映像なんですが、そこに自分が財布を置いた時、触った時の体の感覚も入ってる感じです</td>\n",
       "      <td>NaN</td>\n",
       "      <td>イメージと自分の言葉に加えて、食べたいかどうかを味を想像して考えてる気がします</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>音声と文字のどちらかだけではなく、組み合わさっていると思う。</td>\n",
       "      <td>頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        wallet_answer car_answer  \\\n",
       "5                                                 NaN        NaN   \n",
       "11                   自分の動きを考えるときは、漫画のネームみたいな感じで思い浮かべる        NaN   \n",
       "14                                                NaN        NaN   \n",
       "24  基本は回答した通り映像なんですが、そこに自分が財布を置いた時、触った時の体の感覚も入ってる感じです        NaN   \n",
       "26                                                NaN        NaN   \n",
       "\n",
       "                               lunch_answer  \\\n",
       "5                                       NaN   \n",
       "11                                      NaN   \n",
       "14           味と匂いを想像し、それをいま自分が欲しているのかを自らに問う   \n",
       "24  イメージと自分の言葉に加えて、食べたいかどうかを味を想像して考えてる気がします   \n",
       "26           音声と文字のどちらかだけではなく、組み合わさっていると思う。   \n",
       "\n",
       "                                    reflection_answer  \n",
       "5   頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り...  \n",
       "11                                                NaN  \n",
       "14  他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラ...  \n",
       "24                                                NaN  \n",
       "26  頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove non_numeric_cols[0], non_numeric_cols[1], non_numeric_cols[2] from df_non_numeric\n",
    "df_non_numeric = df_non_numeric.drop(columns=[non_numeric_cols[0], non_numeric_cols[1], non_numeric_cols[2]])\n",
    "\n",
    "\n",
    "#remove all participants that have NaN in all columns from df_non_numeric\n",
    "print(len(df_non_numeric)) #before removing NaNs\n",
    "df_non_numeric = df_non_numeric.dropna(how='all')\n",
    "print(len(df_non_numeric)) #after removing NaNs\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "#update non_numeric_cols to reflect the removal of non_numeric_cols[0], non_numeric_cols[1], non_numeric_cols[2]\n",
    "non_numeric_cols = df_non_numeric.columns\n",
    "#remane text reports cols for clarity:\n",
    "df_non_numeric = df_non_numeric.rename(columns={non_numeric_cols[0]: 'wallet_answer'})\n",
    "df_non_numeric = df_non_numeric.rename(columns={non_numeric_cols[1]: 'car_answer'})\n",
    "df_non_numeric = df_non_numeric.rename(columns={non_numeric_cols[2]: 'lunch_answer'})\n",
    "df_non_numeric = df_non_numeric.rename(columns={non_numeric_cols[3]: 'reflection_answer'})\n",
    "\n",
    "df_non_numeric.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1979 reports in total, from N = 1313 participants\n"
     ]
    }
   ],
   "source": [
    "#list of reflection_answer, and remove NaN values\n",
    "wallet_reports = df_non_numeric['wallet_answer'].dropna()\n",
    "car_reports = df_non_numeric['car_answer'].dropna()\n",
    "lunch_reports = df_non_numeric['lunch_answer'].dropna()\n",
    "df_reports = df_non_numeric['reflection_answer'].dropna()\n",
    "\n",
    "all_reports = pd.concat([wallet_reports, car_reports, lunch_reports, df_reports])\n",
    "print(f\"N = {len(all_reports)} reports in total, from N = {len(df_non_numeric)} participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り面白かった。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 731 reflection reports\n",
      "N = 1979 free text reports in total\n"
     ]
    }
   ],
   "source": [
    "all_reflection_reports = all_reports.tolist() #all free text reports, including wallet, car, lunch, and reflection\n",
    "reflection_reports = df_reports.tolist() #only reflection reports\n",
    "\n",
    "print(f\"N = {len(reflection_reports)} reflection reports\")\n",
    "print(f\"N = {len(all_reflection_reports)} free text reports in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all_reports to /Users/rbeaute/Projects/MOSAIC/DATA/multilingual/japanese/innerspeech/innerspeech_all_reports.csv\n",
      "Saved df_reports to /Users/rbeaute/Projects/MOSAIC/DATA/multilingual/japanese/innerspeech/innerspeech_reflection_reports.csv\n"
     ]
    }
   ],
   "source": [
    "# Save all_reports to CSV\n",
    "all_reports_path = os.path.join(DATA_dir, f\"{dataset}_all_reports.csv\")\n",
    "all_reports.to_csv(all_reports_path, index=False, header=True)\n",
    "print(f\"Saved all_reports to {all_reports_path}\")\n",
    "\n",
    "# Save df_reports to CSV\n",
    "df_reports_path = os.path.join(DATA_dir, f\"{dataset}_reflection_reports.csv\")\n",
    "df_reports.to_csv(df_reports_path, index=True, header=True)\n",
    "print(f\"Saved df_reports to {df_reports_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り...\n",
       "14      他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラ...\n",
       "26      頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字...\n",
       "35      自動思考というものなのか、直近で起きた失敗などを批判する考えが勝手に浮かんできたりすることが...\n",
       "41      食べたいもの、欲しいものなどは、自分がそれを食べている、或いは使っているところを想像して決め...\n",
       "                              ...                        \n",
       "5327    活字を読む時、内言を再生しないとほとんど意味として解されない感覚が通常かと思っていたが、以前...\n",
       "5328    視覚の内言はどの程度鮮明なイメージとして認識ができるか。私の場合はイメージは目で見るようなイ...\n",
       "5332    ことばや概念を思い出すとき、空中に指先で矩形を切る（想像をする）癖があり、ゲームなどのローデ...\n",
       "5340                             フリック入力の感覚など、身体動作の内言？もある。\n",
       "5345    常にどれか一つの内言のみではなく、状況によっては、映像優位になったり自問自答音声が優先された...\n",
       "Name: reflection_answer, Length: 731, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw reports to /Users/rbeaute/Projects/MOSAIC/DATA/multilingual/japanese/innerspeech/innerspeech_reports.pkl\n",
      "Saved all reports to /Users/rbeaute/Projects/MOSAIC/DATA/multilingual/japanese/innerspeech/innerspeech_all_reports.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#save reflections reports to pickle file\n",
    "reports_path = os.path.join(DATA_dir,f\"{dataset}_reports.pkl\")\n",
    "with open(reports_path, 'wb') as f:\n",
    "    pickle.dump(reflection_reports, f)\n",
    "print(f\"Saved raw reports to {reports_path}\")\n",
    "\n",
    "\n",
    "# save all reports to pickle file\n",
    "reports_path = os.path.join(DATA_dir,f\"{dataset}_all_reports.pkl\")\n",
    "with open(reports_path, 'wb') as f:\n",
    "    pickle.dump(all_reflection_reports, f)\n",
    "print(f\"Saved all reports to {reports_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り面白かった。',\n",
       " '他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラメータチューニングかA/Bテストかを繰り返すことでその人の脳内の声を具現化することってできますかね？（具現化しようとした途端に霞をつかむようにとらえどころのないものになってしまうなどの可能性もあるかもなあと思いつつ）',\n",
       " '頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字か音声かと言われると、どちらも混ざっている感じがする。\\n映像や味などは思い出される事がある。',\n",
       " '自動思考というものなのか、直近で起きた失敗などを批判する考えが勝手に浮かんできたりすることがあるが、自分の声とか他人の声という認識はしていなかった。',\n",
       " '食べたいもの、欲しいものなどは、自分がそれを食べている、或いは使っているところを想像して決めているような感じでした。逆に、どこに置いたかな、というのは「自分が置いたときのイメージが湧かないからこそそういう状況になっている」ときは言葉で、「場面を辿ればわかる」ときは映像で思い浮かぶ感じでした。\\n発達系の話になりますが視覚優位か聴覚優位かなどによっても変わりそうで面白いなと思いました。',\n",
       " '画像や映像が頭の中に流れ、その後に自分の声で考える事が多い。',\n",
       " 'フローチャートや箇条書きで考えるのは便利そうなので意識的にやってみたい。',\n",
       " 'キャスト全員が自分の声で話しているボイスドラマを聴いている風に内言します。',\n",
       " '思考中にふと反対意見・対立意見が他人の声で聞こえる',\n",
       " '言葉にできないことが多い。説明や言葉が足りず、内容を人に理解させることが難しい。',\n",
       " 'この度は面白いテーマでのアンケートの機会をいただきありがとうございます。アンケートを通じて改めて、黙読している時も、文章を書いている時も必ず内言が生じていることに気づきました。アンケートの内容からそうではない人がいるのだということも知ることができ、大変面白くもありました。',\n",
       " '五感のどれをどのくらい使うかは、場合による。',\n",
       " 'イメージだけを提示する別の自分と会話している感じはする',\n",
       " '全体的に「言われてみればこう考えているかもしれない」という印象でした。\\n振り返ってみると、具体的な言葉や絵ではないもっと抽象的な感覚を含んでいると思います。\\nそれが最後の「どれだけ自分自身の内言を鮮明に自覚できますか？」に対する回答の値「2」です。\\n抽象的な感覚があるからこそ、ひらめくという処理ができるのだと思うし、具体的なイメージよりも高速な処理ができるような気がします。\\n※これはあくまで私見で、妄想のようなものと思ってください。',\n",
       " '研究応援しています！！！！！',\n",
       " '言葉を伴わない場合や映像を伴わず抽象的なイメージで思考していることがよくあります',\n",
       " 'このような研究があるのは面白いですね。内言についてもっと知りたいと思いました。',\n",
       " '人と会話しているときは自分の声で思考していますが、さまざまな考え事を一人でするときは頭の中に自分と他者がおり対話することが多いです。',\n",
       " '心理学で「内言」がどのような定義か知らないのですが、思考のうち自覚的に行っている部分、というイメージで回答していました。そのため、後半の、内言がどの程度自覚的なものかという設問は意外に感じました（そういうパターンがあるということでしょうか）。',\n",
       " 'テーマの種類と、関連する経験や記憶によって、内言が視覚的になったり音声的になったり文字情報になったりと変化する気がします。']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflection_reports[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
