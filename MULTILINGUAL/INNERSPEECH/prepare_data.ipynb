{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd663e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOX_ROOT  : /Users/rb666/Library/CloudStorage/Box-Box/TMDATA\n",
      "RAW_DIR   : /Users/rb666/Library/CloudStorage/Box-Box/TMDATA/INNERSPEECH\n",
      "LOCAL_DATA: /Users/rb666/Projects/MOSAIC/DATA/innerspeech\n",
      "PREPROC   : /Users/rb666/Projects/MOSAIC/DATA/innerspeech/preprocessed\n",
      "CACHE_DIR : /Users/rb666/Projects/MOSAIC/DATA/innerspeech/preprocessed/cache\n"
     ]
    }
   ],
   "source": [
    "# --- paths & setup (portable) ---\n",
    "from pathlib import Path\n",
    "import os, json, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from mosaic.path_utils import CFG, raw_path, proc_path, project_root\n",
    "\n",
    "# RAW Box folder name for this dataset\n",
    "DATASET_RAW = \"INNERSPEECH\"   \n",
    "# Processed target: ~/.../DATA/innerspeech/preprocessed\n",
    "LOCAL_DATA_DIR = proc_path(str(DATASET_RAW).lower())\n",
    "PREPROC_DIR = proc_path(str(DATASET_RAW).lower(), \"preprocessed\")\n",
    "CACHE_DIR   = PREPROC_DIR / \"cache\"\n",
    "\n",
    "# (optional) repo-root helpers if want to import local modules\n",
    "ROOT = project_root()\n",
    "\n",
    "# make sure dirs exist\n",
    "PREPROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_DIR = raw_path(DATASET_RAW)\n",
    "\n",
    "print(\"BOX_ROOT  :\", CFG[\"box_root\"])\n",
    "print(\"RAW_DIR   :\", RAW_DIR)\n",
    "print(\"LOCAL_DATA:\", LOCAL_DATA_DIR)\n",
    "print(\"PREPROC   :\", PREPROC_DIR)\n",
    "print(\"CACHE_DIR :\", CACHE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17db39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: /Users/rb666/Projects/MOSAIC/DATA/innerspeech/innerspeech_reflection_reports.csv\n",
      "Loaded 731 reports from /Users/rb666/Projects/MOSAIC/DATA/innerspeech/innerspeech_reflection_reports.csv\n",
      "(731, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reflection_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>自動思考というものなのか、直近で起きた失敗などを批判する考えが勝手に浮かんできたりすることが...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>食べたいもの、欲しいものなどは、自分がそれを食べている、或いは使っているところを想像して決め...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   reflection_answer\n",
       "0  頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り...\n",
       "1  他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラ...\n",
       "2  頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字...\n",
       "3  自動思考というものなのか、直近で起きた失敗などを批判する考えが勝手に浮かんできたりすることが...\n",
       "4  食べたいもの、欲しいものなどは、自分がそれを食べている、或いは使っているところを想像して決め..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load reflection reports CSV ---\n",
    "csv_path = os.path.join(LOCAL_DATA_DIR, f\"{str(DATASET_RAW).lower()}_reflection_reports.csv\")\n",
    "print(\"CSV:\", csv_path)\n",
    "\n",
    "if not Path(csv_path).exists():\n",
    "    raise FileNotFoundError(f\"Missing file: {csv_path}\")\n",
    "\n",
    "#load only the reflection_answers column\n",
    "df = pd.read_csv(csv_path, usecols=[\"reflection_answer\"])\n",
    "n_reports = df.shape[0]\n",
    "print(f\"Loaded {n_reports} reports from {csv_path}\")\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195b41a",
   "metadata": {},
   "source": [
    "### Sample translate .csv file multilangual into English (using Gemini API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.api_core import exceptions\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "\n",
    "# --- SETUP AND CONFIGURATION ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please set the GOOGLE_API_KEY in your .env file.\")\n",
    "\n",
    "def _configure_gemini(api_key: str):\n",
    "    # Prefer v1; if this SDK doesn’t accept api_version, just ignore\n",
    "    try:\n",
    "        genai.configure(api_key=api_key, api_version=\"v1\")\n",
    "    except TypeError:\n",
    "        genai.configure(api_key=api_key)\n",
    "    # sanity: show where we ended up\n",
    "    try:\n",
    "        info = genai.get_model(\"models/gemini-info\")\n",
    "        # not all SDKs have this; ignore if it fails\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "_configure_gemini(api_key)\n",
    "\n",
    "\n",
    "\n",
    "def pick_model(preferred=(\n",
    "    # Prefer modern, available names first (as listed by your SDK)\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-flash-latest\",\n",
    "    \"gemini-2.5-pro\",\n",
    "    # fallbacks (keep if your tenant exposes them)\n",
    "    \"gemini-2.0-flash\",\n",
    "    \"gemini-pro-latest\",\n",
    "    # legacy aliases last\n",
    "    \"gemini-1.5-flash-002\",\n",
    "    \"gemini-1.5-pro-002\",\n",
    ")):\n",
    "    avail = {}\n",
    "    try:\n",
    "        for m in genai.list_models():\n",
    "            methods = set(getattr(m, \"supported_generation_methods\", []) or [])\n",
    "            name = m.name.split(\"/\")[-1]\n",
    "            if \"generateContent\" in methods:\n",
    "                avail[name] = True\n",
    "                # uncomment if you want to see what’s available\n",
    "                # print(f\"- {name} supports: {sorted(methods)}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not list models:\", e)\n",
    "\n",
    "    # 1) choose the first preferred that is available\n",
    "    for name in preferred:\n",
    "        if not avail or name in avail:\n",
    "            print(\"Using model:\", name)\n",
    "            return name\n",
    "\n",
    "    # 2) if none of the preferred names matched but we DO have availables,\n",
    "    #    pick a sensible fast default from what we saw.\n",
    "    if avail:\n",
    "        for candidate in (\"gemini-2.5-flash\", \"gemini-flash-latest\"):\n",
    "            if candidate in avail:\n",
    "                print(\"Using model:\", candidate)\n",
    "                return candidate\n",
    "        # otherwise just pick any available\n",
    "        picked = next(iter(avail.keys()))\n",
    "        print(\"Using available model:\", picked)\n",
    "        return picked\n",
    "\n",
    "    print(\"Falling back to gemini-2.5-flash\")\n",
    "    return \"gemini-2.5-flash\"\n",
    "\n",
    "chosen_model_name = pick_model()\n",
    "model = genai.GenerativeModel(model_name=chosen_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "366dc6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 731 entries into 37 batches of up to 20 each.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches: 100%|██████████| 37/37 [18:02<00:00, 29.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Translation Results (First 5 Rows) ---\n",
      "                                   reflection_answer  \\\n",
      "0  頭の中の独り言をこのような調査で改めて自覚することができ、また色々なパターンがあることを知り...   \n",
      "1  他人の声が脳内でしている人がいるという話にすごく興味があるのですが、心理物理実験で音声のパラ...   \n",
      "2  頭の中では日本語で考えているという自覚はある（英語は勉強以外にほぼ使ったことはない）が、文字...   \n",
      "3  自動思考というものなのか、直近で起きた失敗などを批判する考えが勝手に浮かんできたりすることが...   \n",
      "4  食べたいもの、欲しいものなどは、自分がそれを食べている、或いは使っているところを想像して決め...   \n",
      "\n",
      "                           reflection_answer_english  \n",
      "0  Through this survey, I was able to re-recogniz...  \n",
      "1  I'm very interested in the idea that some peop...  \n",
      "2  I am aware that I think in Japanese in my head...  \n",
      "3  Perhaps it's automatic thought, but ideas crit...  \n",
      "4  When deciding what I want to eat or what I wan...  \n",
      "\n",
      "Translated data saved to /Users/rb666/Projects/MOSAIC/DATA/innerspeech/preprocessed/innerspeech_translated_batched_API.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- BATCH TRANSLATION FUNCTION WITH EXPONENTIAL BACKOFF ---\n",
    "def translate_batch_with_retry(texts: list[str], max_retries: int = 3) -> list[str]:\n",
    "    \"\"\"\n",
    "    Translates a BATCH of texts, with automatic retries for rate limit errors.\n",
    "    \"\"\"\n",
    "    numbered_texts = \"\\n\".join([f'\"{i+1}\": \"{text}\"' for i, text in enumerate(texts)])\n",
    "    prompt = f\"\"\"Translate each of the following numbered Japanese texts to English.\n",
    "Please return the result as a single, valid JSON object where keys are the numbers and values are the English translations.\n",
    "The JSON object should have exactly {len(texts)} elements. Do not include any other explanatory text in your response.\n",
    "\n",
    "TEXTS TO TRANSLATE:\n",
    "{{\n",
    "{numbered_texts}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            cleaned = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            translated_dict = json.loads(cleaned)\n",
    "            translated_texts = [translated_dict.get(str(i+1), \"Error: Missing translation\") for i in range(len(texts))]\n",
    "            if len(translated_texts) == len(texts):\n",
    "                return translated_texts\n",
    "            return [\"Error: Mismatch in batch response\"] * len(texts)\n",
    "\n",
    "        except exceptions.ResourceExhausted:\n",
    "            wait_s = 15 * (2 ** attempt) + random.uniform(0, 1)  # backoff + jitter\n",
    "            print(f\"Rate limit exceeded. Waiting {wait_s:.1f}s (attempt {attempt+1}/{max_retries})\")\n",
    "            time.sleep(wait_s)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error during batch translation: {e}\")\n",
    "            return [f\"Error: {e}\"] * len(texts)\n",
    "\n",
    "    print(\"All retries failed for this batch.\")\n",
    "    return [\"Error: Max retries exceeded\"] * len(texts)\n",
    "\n",
    "\n",
    "\n",
    "# --- EXECUTE THE BATCHED TRANSLATION ---\n",
    "if not df.empty:\n",
    "    BATCH_SIZE = 20\n",
    "    all_translations = []\n",
    "\n",
    "    series = df['reflection_answer'].dropna().astype(str)\n",
    "    # split into batches of up to BATCH_SIZE\n",
    "    batches = [series.iloc[i:i+BATCH_SIZE] for i in range(0, len(series), BATCH_SIZE)]\n",
    "    print(f\"Split {len(series)} entries into {len(batches)} batches of up to {BATCH_SIZE} each.\")\n",
    "\n",
    "    for batch in tqdm(batches, desc=\"Translating Batches\"):\n",
    "        translations = translate_batch_with_retry(batch.tolist())\n",
    "        all_translations.extend(translations)\n",
    "        time.sleep(1)  # gentle pacing\n",
    "\n",
    "    # align back to df indices\n",
    "    df = df.copy()\n",
    "    df.loc[series.index, 'reflection_answer_english'] = all_translations\n",
    "\n",
    "    # --- REVIEW AND SAVE RESULTS ---\n",
    "    print(\"\\n--- Translation Results (First 5 Rows) ---\")\n",
    "    print(df[['reflection_answer', 'reflection_answer_english']].head())\n",
    "\n",
    "    # SAVE translated CSV into preprocessed folder\n",
    "    translated_csv = PREPROC_DIR / \"innerspeech_translated_batched_API.csv\"\n",
    "    df.to_csv(translated_csv, index=False)\n",
    "    print(f\"\\nTranslated data saved to {translated_csv}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty, skipping translation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836440dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_n = min(10, len(df))\n",
    "for i in range(preview_n):\n",
    "    print(f\"--- Document {i} ---\")\n",
    "    orig = df.iloc[i]['reflection_answer']\n",
    "    trans = df.iloc[i].get('reflection_answer_english', None)\n",
    "    print(\"Original :\", orig if isinstance(orig, str) else str(orig))\n",
    "    print(\"Translated:\", trans if isinstance(trans, str) else \"(no translation)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a1bf47",
   "metadata": {},
   "source": [
    "### Divide into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# # ----------------------------------------\n",
    "# reports = df['reflection_answer_english'].tolist()\n",
    "# print(f\"Loaded {len(reports)} (translated) documents for BERTopic modeling.\")\n",
    "# # ----------------------------------------\n",
    "# # Divide each report into sentences\n",
    "# reports_sentences = [nltk.sent_tokenize(report) for report in reports]\n",
    "\n",
    "# # Calculate the total number of sentences\n",
    "# sentences_per_report = [len(report) for report in reports_sentences] #keep track of the number of sentences in each report (for further analysis)\n",
    "# print(f\"Number of sentences in each report (mapping): {sentences_per_report}\")\n",
    "# print(f\"Total number of sentences: {sum(sentences_per_report)}\")\n",
    "\n",
    "\n",
    "# all_sentences = [sentence for report in reports_sentences for sentence in report]\n",
    "# print(f\"Total number of sentences across all reports: {len(all_sentences)}\") #sanity check, should match the sum above\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Divide into sentences\n",
    "\n",
    "# %%\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Choose text source: prefer translated, else fall back to original\n",
    "if 'reflection_answer_english' in df.columns and df['reflection_answer_english'].notna().any():\n",
    "    reports = df['reflection_answer_english'].fillna(\"\").astype(str).tolist()\n",
    "    print(\"Using translated English text for sentence splitting.\")\n",
    "else:\n",
    "    reports = df['reflection_answer'].fillna(\"\").astype(str).tolist()\n",
    "    print(\"Using original text for sentence splitting.\")\n",
    "\n",
    "print(f\"Loaded {len(reports)} documents for sentence splitting.\")\n",
    "\n",
    "# Split into sentences\n",
    "reports_sentences = [nltk.sent_tokenize(report) for report in reports]\n",
    "\n",
    "# Sentence counts\n",
    "sentences_per_report = [len(report) for report in reports_sentences]\n",
    "total_sentences = sum(sentences_per_report)\n",
    "print(f\"Number of sentences in each report (mapping): {sentences_per_report}\")\n",
    "print(f\"Total number of sentences: {total_sentences}\")\n",
    "\n",
    "all_sentences = [sentence for report in reports_sentences for sentence in report]\n",
    "print(f\"Total number of sentences across all reports: {len(all_sentences)}\")  # sanity check\n",
    "\n",
    "# Optionally cache the sentences for downstream steps\n",
    "np.save(CACHE_DIR / \"docs_sentences.npy\", np.array(all_sentences, dtype=object))\n",
    "print(\"Saved sentences →\", CACHE_DIR / \"docs_sentences.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309675d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate stats for the distribution of sentences per report\n",
    "sentences_array = np.array(sentences_per_report)\n",
    "mean_sentences = np.mean(sentences_array)\n",
    "median_sentences = np.median(sentences_array)\n",
    "std_sentences = np.std(sentences_array)\n",
    "min_sentences = np.min(sentences_array)\n",
    "max_sentences = np.max(sentences_array)\n",
    "\n",
    "print(f\"Mean sentences per report: {mean_sentences:.2f}\")\n",
    "print(f\"Median sentences per report: {median_sentences}\")\n",
    "print(f\"Standard deviation: {std_sentences:.2f}\")\n",
    "print(f\"Minimum sentences in a report: {min_sentences}\")\n",
    "print(f\"Maximum sentences in a report: {max_sentences}\")\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(sentences_array, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Sentences per Report')\n",
    "plt.xlabel('Number of Sentences')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Plot boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(sentences_array, vert=False)\n",
    "plt.title('Boxplot of Sentences per Report')\n",
    "plt.xlabel('Number of Sentences')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig_path = PREPROC_DIR / \"sentences_per_report_stats.png\"\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(\"Saved figure →\", fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Calculate outlier thresholds using IQR method\n",
    "sentences_array = np.array(sentences_per_report)\n",
    "Q1 = np.percentile(sentences_array, 25)\n",
    "Q3 = np.percentile(sentences_array, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Find indices of outlier reports\n",
    "outlier_indices = np.where((sentences_array < lower_bound) | (sentences_array > upper_bound))[0]\n",
    "\n",
    "print(f\"Number of outlier reports (by sentence count): {len(outlier_indices)}\")\n",
    "\n",
    "# Print content of outlier reports\n",
    "for idx in outlier_indices[:20]:  # avoid spamming if many\n",
    "    print(f\"\\nReport index: {idx}, Sentence count: {sentences_array[idx]}\")\n",
    "    print(\"Sentences:\")\n",
    "    for sent in reports_sentences[idx]:\n",
    "        print(f\"- {sent}\")\n",
    "\n",
    "# Optional: save outlier indices\n",
    "np.save(CACHE_DIR / \"outlier_report_indices.npy\", outlier_indices)\n",
    "print(\"Saved outlier indices →\", CACHE_DIR / \"outlier_report_indices.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mosaicvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
